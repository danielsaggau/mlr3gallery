<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mlr3 gallery</title>
    <link>/</link>
    <description>Recent content on mlr3 gallery</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Encode factor levels for xgboost</title>
      <link>/encode-factors-for-xgboost/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/encode-factors-for-xgboost/</guid>
      <description>The package xgboost unfortunately does not support handling of categorical features. Therefore it is required to manually convert factor columns to numerical dummy features. We show how to use mlr3pipelines to augment the xgboost learner with an automatic factor encoding.
Construct the Base Objects First, we take an example task with factors (german_credit) and create the xgboost learner:
library(mlr3) library(mlr3learners) task = tsk(&amp;quot;german_credit&amp;quot;) print(task) ## &amp;lt;TaskClassif:german_credit&amp;gt; (1000 x 21) ## * Target: credit_risk ## * Properties: twoclass ## * Features (20): ## - fct (12): credit_history, foreign_worker, housing, job, ## other_debtors, other_installment_plans, personal_status_sex, ## property, purpose, savings, status, telephone ## - dbl (7): age, amount, duration, installment_rate, number_credits, ## people_liable, present_residence ## - ord (1): employment_duration learner = lrn(&amp;quot;classif.</description>
    </item>
    
    <item>
      <title>House prices in King County</title>
      <link>/house-prices-in-king-county/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/house-prices-in-king-county/</guid>
      <description>This use case shows how to model housing price data in King County. Following features are illustrated:
 Summarizing the data set Converting data to treat it as a numeric feature/factor Generating new variables Splitting data into train and test data sets Computing a first model (decision tree) Building many trees (random forest) Visualizing price data across different region Optimizing the baseline by implementing a tuner Engineering features Creating a sparser model  House Price Prediction in King County We use the house_sales_prediction dataset contained in the package mlr3book in order to provide a use-case for the application of mlr3 on real-world data.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>This gallery provides examples and case studies for mlr3.
If you want to contribute, just create a pull request on GitHub with a blogdown article.</description>
    </item>
    
  </channel>
</rss>