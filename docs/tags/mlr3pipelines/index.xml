<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mlr3pipelines on mlr3 gallery</title>
    <link>/tags/mlr3pipelines/</link>
    <description>Recent content in mlr3pipelines on mlr3 gallery</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/mlr3pipelines/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Encode factor levels for xgboost</title>
      <link>/encode-factors-for-xgboost/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/encode-factors-for-xgboost/</guid>
      <description>The package xgboost unfortunately does not support handling of factor levels. Therefore it is required to manually convert factor features to numerical dummy features. We show how to use mlr3pipelines to augment the xgboost learner with an automatic factor encoding.
Construct the Base Objects First, we create an example task with factors (german_credit) and the xgboost learner:
library(mlr3) library(mlr3learners) task = tsk(&amp;quot;german_credit&amp;quot;) print(task) ## &amp;lt;TaskClassif:german_credit&amp;gt; (1000 x 21) ## * Target: credit_risk ## * Properties: twoclass ## * Features (20): ## - fct (12): credit_history, foreign_worker, housing, job, ## other_debtors, other_installment_plans, personal_status_sex, ## property, purpose, savings, status, telephone ## - dbl (7): age, amount, duration, installment_rate, number_credits, ## people_liable, present_residence ## - ord (1): employment_duration learner = lrn(&amp;quot;classif.</description>
    </item>
    
  </channel>
</rss>